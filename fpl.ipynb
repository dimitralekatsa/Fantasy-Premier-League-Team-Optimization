{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286779e7",
   "metadata": {},
   "source": [
    "# FPL Prediction Pipeline\n",
    "\n",
    "This notebook runs the complete FPL prediction pipeline including data fetching, feature engineering, model training, predictions and team optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b21392",
   "metadata": {},
   "source": [
    "### Quick Start\n",
    "\n",
    "This notebook supports two workflows:\n",
    "- **Train New Model**: Full pipeline including model training\n",
    "- **Use Existing Model**: Load a pre-trained model and generate predictions\n",
    "\n",
    "Both require:\n",
    "1. Data fetching and feature processing (Common Setup)\n",
    "2. Model (train new or load existing)\n",
    "3. Prediction generation\n",
    "4. Team optimization (optional, requires team ID for transfers)\n",
    "\n",
    "### Alternative: Command Line\n",
    "\n",
    "You can also run the pipeline from command line:\n",
    "\n",
    "- Full pipeline:\n",
    "```bash\n",
    "python main.py --team-id YOUR_TEAM_ID\n",
    "```\n",
    "- Full pipeline with adjusted budget (for starters):\n",
    "```bash\n",
    "python main.py --team-id YOUR_TEAM_ID --budget YOUR_BUDGET\n",
    "```\n",
    "- Training and Prediction pipeline without team optimization\n",
    "```bash\n",
    "python main.py --skip-optimization\n",
    "```\n",
    "- Team Optimization only (if you already generated predictions)\n",
    "```bash\n",
    "python main.py --skip-pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348fb91",
   "metadata": {},
   "source": [
    "## ⚠️ Important Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f1b9db",
   "metadata": {},
   "source": [
    "### **Note on `initial_transfers` configuration**\n",
    "\n",
    "The `initial_transfers` parameter can be set to `\"auto\"` in order to infer the number of available transfers at the start of the optimization horizon.\n",
    "\n",
    "This option assumes that the manager has **not previously used Wildcard or Free Hit** during the current season.\n",
    "\n",
    "If either of these chips has already been used, the automatic inference may be incorrect due to the way FPL transfer carryover rules are applied.  \n",
    "In such cases, it is recommended to **explicitly set `initial_transfers` in `config.yaml`** (e.g. `initial_transfers: 1`), as done in the current configuration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb655",
   "metadata": {},
   "source": [
    "### **Seasons \"21-22\" and earlier do not have `expected_*` columns.**\n",
    "If training on these older seasons, you must exclude all features containing `\"expected_\"`\n",
    "\n",
    "If you include these older seasons in your `past_seasons` config, you must filter out all `expected_*` features before training.\n",
    "\n",
    "Run this code **after the common setup section and before training**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c1b6b",
   "metadata": {},
   "source": [
    "```python\n",
    "import features\n",
    "\n",
    "fe_config = pipeline.config[\"feature_engineering\"]\n",
    "\n",
    "# Get feature list based on scaling configuration\n",
    "if fe_config[\"scale_features\"]:\n",
    "    feature_list = features.get_feature_set(fe_config[\"rolling_window\"], fe_config[\"difficulty_window\"],\n",
    "                                            fe_config[\"team_window\"], fe_config[\"form_window\"], True)\n",
    "else:\n",
    "    feature_list = features.get_feature_set(fe_config[\"rolling_window\"], fe_config[\"difficulty_window\"],\n",
    "                                            fe_config[\"team_window\"], fe_config[\"form_window\"], False)\n",
    "\n",
    "# Filter out expected_ features\n",
    "feature_list = [f for f in feature_list if \"expected_\" not in f]\n",
    "\n",
    "rolling_columns = features.get_rolling_features(fe_config[\"rolling_window\"])\n",
    "rolling_columns = [f for f in rolling_columns if \"expected_\" not in f]\n",
    "\n",
    "difficulty_columns = features.get_difficulty_features(fe_config[\"difficulty_window\"])\n",
    "difficulty_columns = [f for f in difficulty_columns if \"expected_\" not in f]\n",
    "\n",
    "# Pass these filtered lists to train_model()\n",
    "model = pipeline.train_model(\n",
    "    feature_list=feature_list,\n",
    "    rolling_cols=rolling_columns,\n",
    "    difficulty_cols=difficulty_columns\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf08d5d",
   "metadata": {},
   "source": [
    "**Alternative:** Remove seasons \"21-22\" and earlier from your config.yaml past_seasons list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbc50ae",
   "metadata": {},
   "source": [
    "# Training / Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e557ca",
   "metadata": {},
   "source": [
    "## Workflow 1: Train New Model\n",
    "\n",
    "Run this if you want to train a new model to generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a843f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl.main import FPLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FPLPipeline(config_path=\"config.yaml\")\n",
    "\n",
    "pipeline.fetch_past_data()\n",
    "pipeline.fetch_current_data()\n",
    "past_gws_df = pipeline.process_past_data()\n",
    "\n",
    "if \"code\" in pipeline.config[\"model\"][\"categorical_features\"]:\n",
    "    pipeline.training_data = pipeline.training_data[\n",
    "        pipeline.training_data.code.isin(\n",
    "            pipeline.training_data[pipeline.training_data.season == pipeline.training_data.season.max()].code.unique()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "pipeline.fetch_future_data()\n",
    "future_gws_df = pipeline.process_future_data()\n",
    "\n",
    "\n",
    "feature_list = pipeline.config[\"feature_engineering\"][\"feature_set\"]\n",
    "nan_summary_past = past_gws_df[feature_list].isnull().sum()\n",
    "nan_summary_future = future_gws_df[feature_list].isnull().sum()\n",
    "print(f\"Columns with NaN values (past dataset):\\n{nan_summary_past[nan_summary_past > 0]}\")\n",
    "print(f\"Columns with NaN values (future dataset):\\n{nan_summary_future[nan_summary_future > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.generate_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d704bae",
   "metadata": {},
   "source": [
    "## Workflow 2: Use Existing Model (skip training)\n",
    "Run this if you have a pre-trained model and just want predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl.main import FPLPipeline\n",
    "from fpl.utils.utils import handle_double_gameweeks\n",
    "from fpl.models.rf_models import RandomForest\n",
    "from fpl.models.gbm_models import GradientBoosting\n",
    "from fpl.models.lgbm_models import LightGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = FPLPipeline(config_path=\"config.yaml\")\n",
    "\n",
    "pipeline.fetch_past_data()\n",
    "pipeline.fetch_current_data()\n",
    "past_gws_df = pipeline.process_past_data()\n",
    "\n",
    "if \"code\" in pipeline.config[\"model\"][\"categorical_features\"]:\n",
    "    pipeline.training_data = pipeline.training_data[\n",
    "        pipeline.training_data.code.isin(\n",
    "            pipeline.training_data[pipeline.training_data.season == pipeline.training_data.season.max()].code.unique()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "pipeline.fetch_future_data()\n",
    "future_gws_df = pipeline.process_future_data()\n",
    "\n",
    "feature_list = pipeline.config[\"feature_engineering\"][\"feature_set\"]\n",
    "nan_summary = past_gws_df[feature_list].isnull().sum()\n",
    "print(f\"Columns with NaN values:\\n{nan_summary[nan_summary > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6658577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the name of the saved model and it's type\n",
    "model = GradientBoosting.from_saved_model(\"models/gb_model_gw18.pkl\")\n",
    "\n",
    "preds = model.predict(X=pipeline.future_data)\n",
    "\n",
    "pipeline.predictions = handle_double_gameweeks(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2042407",
   "metadata": {},
   "source": [
    "# Team Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f77b48",
   "metadata": {},
   "source": [
    "You do not need your team ID:\n",
    "1. First gameweek of the season (Wildcard Optimization automatically)\n",
    "\n",
    "2. If you want to use the wildcard chip (change in the config the use_wildcard: true or run the Wildcard Optimization subsection below)\n",
    "\n",
    "3. If you want to use the freehit chip (change in the config the use_freehit: true or run the Free Hit Optimization subsection below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd24bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id = pipeline.config.get(\"TEAM_ID\")\n",
    "result = pipeline.optimize_team(team_id=team_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e0c6c",
   "metadata": {},
   "source": [
    "## Wildcard Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl.optimization.team_selection import WildcardOptimization\n",
    "\n",
    "wildcard = WildcardOptimization(\n",
    "    predictions_df=pipeline.predictions,\n",
    "    budget=pipeline.config[\"team_selection\"][\"wildcard\"][\"budget\"],\n",
    "    valid_status=pipeline.config[\"team_selection\"][\"valid_status\"],\n",
    "    num_starters=pipeline.config[\"team_selection\"][\"wildcard\"][\"num_starters\"],\n",
    "    future_weights=pipeline.config[\"team_selection\"][\"wildcard\"][\"future_weights\"]\n",
    ")\n",
    "\n",
    "optimal_team_df, optimal_starters_df = wildcard.optimize_wildcard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217697d2",
   "metadata": {},
   "source": [
    "## Free Hit Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl.optimization.team_selection import FreeHitOptimization\n",
    "\n",
    "freehit = FreeHitOptimization(\n",
    "    predictions_df=pipeline.predictions,\n",
    "    budget=pipeline.config[\"team_selection\"][\"freehit\"][\"budget\"],\n",
    "    valid_status=pipeline.config[\"team_selection\"][\"valid_status\"]\n",
    ")\n",
    "\n",
    "optimal_team_df = freehit.optimize_freehit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
